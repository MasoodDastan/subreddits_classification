{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb2ef18e-4ed7-4744-b1e4-0eb79686963f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pickle\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, regexp_tokenize, RegexpTokenizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, roc_auc_score, RocCurveDisplay, ConfusionMatrixDisplay, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8482825-1326-427b-9b13-223d18e69d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>i want to sell my new car so i can afford to m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>disputing a medical bill i am a healthy indivi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>best credit card for travel i’m getting marrie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>anyone using laurel road? division of key bank...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>signed up for personal advisor service with va...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subreddit                                          full_text\n",
       "0          1  i want to sell my new car so i can afford to m...\n",
       "1          1  disputing a medical bill i am a healthy indivi...\n",
       "2          1  best credit card for travel i’m getting marrie...\n",
       "3          1  anyone using laurel road? division of key bank...\n",
       "4          1  signed up for personal advisor service with va..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../data/reddit_train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eff388d-b9b1-4506-ade1-382428dd9409",
   "metadata": {},
   "source": [
    "## Model preambles\n",
    "\n",
    "In this notebook, all the models will utilize a cross-validated randomized search. This approach allows the models to explore a range of potential hyperparameters and identify the optimal configuration for each model. The following section set up the specific tuning parameters for each model that will be used later in this notebook. Additionally, a KFold cross-validation is initialized, which will be utilized by the models for evaluation.\n",
    "\n",
    "Please ensure that the necessary functions, including `nlp_random_search_modeler`, are imported from the `nlp_functions.py` file located in the current directory before running the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "418e37ba-4b72-4bdf-96ed-eaf6b8166402",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp_functions import nlp_random_search_modeler, lemmatize_text, stem_text, custom_lemmatize, pos_lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9729da42-90cb-4e59-91a5-b509a2b820d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfcf4ee-7859-4f11-964f-ca989003df2e",
   "metadata": {},
   "source": [
    "#### Hyperparameters for the Word Vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a2ac882-43de-4dd4-87ab-d422d249e9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_params = {        \n",
    "    'preprocessor': [None, lemmatize_text, stem_text, pos_lemmatizer], \n",
    "    'max_features':[None, 2250, 2500, 2750, 5750, 6000, 6250, 7750, 8000, 8250, 8500, 9000],\n",
    "    'stop_words': [None, stopwords.words('english')],\n",
    "    'min_df': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'max_df': [0.8, .825, .85, 0.875, 0.9, 0.925, .95],\n",
    "    'ngram_range':[(1,1), (1,2)]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8ca8e9-58f9-4fa6-b5a7-8c893ce96fd3",
   "metadata": {},
   "source": [
    "#### Hyperparameters for the Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45fd5954-0fba-4ccc-9d7c-d01d62f28ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_params = {\n",
    "    'penalty':[None, 'l1', 'l2'], #--> in my trail attempts the default penalty of l2 has been the pick of the randomized search\n",
    "    'C': np.linspace(0.08, 0.15, 20), # again my trail search for optimal hyper parameters this range seems to hold the optimal level of penalty.   \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fa30bf-b90a-4182-8eef-e3617026650d",
   "metadata": {},
   "source": [
    "#### Hyperparameters for the Random Forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa3f82b1-6b35-4db8-9ca5-86ca08ef4762",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = {\n",
    "    'n_estimators': [100, 150, 175, 200, 225, 250],\n",
    "    'max_depth': [None, 65, 70, 75, 80, 85, 90, 95, 100],\n",
    "    'min_samples_split': np.arange(6, 11, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cf571f-aadf-43d2-86f8-fe9921374ca0",
   "metadata": {},
   "source": [
    "#### Hyperparameters for the Support Vector Machine Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae1f6698-5ed8-4663-bd91-91570891608b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://numpy.org/doc/stable/reference/generated/numpy.append.html\n",
    "svc_params={'C': np.append([0.1, 0.5, 1], np.linspace(2, 4, 20)),\n",
    "            'kernel': ['rbf','poly', 'linear'], \n",
    "            'degree' : [2,3,4]\n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65b8e52-b6dc-4550-abb0-b76a9915e966",
   "metadata": {},
   "source": [
    "#### Hyperparameters for the Support Vector Machine Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e47773bb-a4e2-4d22-ba70-af6716793e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_params = {\n",
    "    'learning_rate': [0.1, 0.5, 1, 1.025, 1.05, 1.075, 1.1],\n",
    "    'n_estimators': [100, 125, 150, 170, 175, 180, 185],\n",
    "    'max_features': [None, 'sqrt', 'log2'], #--> sqrt was always the model preferred choice. so I'm adding it to the instantiation\n",
    "    'max_depth': np.append(None, np.arange(1, 21, 2))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013f78de-5443-466a-a480-2eda3b7cf6db",
   "metadata": {},
   "source": [
    "### Training and Validation Split\n",
    "In this section, the training and validation data will be prepared and initialized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d5c1b17-2aa9-4da3-a558-0cefa9549b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['subreddit']\n",
    "X = train['full_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65de2c87-8632-4166-a82e-81b03ba4cd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2aa6cf-2e33-458d-abcc-e229b99f1761",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b66e39b-9ad5-4d3c-abcc-f5bf7b5aac2f",
   "metadata": {},
   "source": [
    "### Baseline Model\n",
    "\n",
    "The baseline accuracy in the sample is 62.5%. The objective of the subsequent models is to achieve higher accuracy and surpass this baseline as much as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6ec187f-4965-4ffb-85bd-2264def9555d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.625264\n",
       "0    0.374736\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffcc35c-27e1-42a5-8e3c-f9db0520cd57",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model Setup\n",
    "By utilizing the `nlp_random_search_modeler` function and incorporating the parameters of the text vectorizers along with the predefined model parameters specified in the model preambles, we are now able to conduct a randomized search across a wide range of hyperparameters. The classification models considered in this search include **Naive Bayes, Logistic Regression, Random Forest, Support Vector Classifier, and Gradient Boosting Classifier.**\n",
    "\n",
    "It is important to note that the values of these hyperparameters have been carefully adjusted by the author through multiple iterations, aiming to determine the optimal range for tuning parameters while also reducing the search time required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d19d03b-b21f-46bf-95bb-2e53723703fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {'nb': {'mod_instant': MultinomialNB(), 'mod_param':None},\n",
    "              'logreg': {'mod_instant': LogisticRegression(solver='liblinear', max_iter= 5000), 'mod_param':logreg_params},\n",
    "              'rf': {'mod_instant': RandomForestClassifier(random_state= 42), 'mod_param':rf_params},\n",
    "              'svc':{'mod_instant': SVC(probability=True), 'mod_param': svc_params},\n",
    "              'gb': {'mod_instant': GradientBoostingClassifier(random_state= 42), 'mod_param':gb_params}           \n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9057560d-4c09-4b4d-809f-6600533dfa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734355f0-7da1-4587-a71c-549c9344085c",
   "metadata": {},
   "source": [
    "The next two code cells below implement a randomized search over all the models specified above, utilizing both CountVectorizer() and TfidfVectorizer(). This process involves training and evaluating the models with different hyperparameter combinations using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25c7d3a0-e232-45e6-b584-facc0ccac96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4h 15min 22s, sys: 1min 49s, total: 4h 17min 11s\n",
      "Wall time: 4h 18min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "models_cvec = {}\n",
    "\n",
    "# Iterate over each key-value pair in the model_dict dictionary\n",
    "for key, dic in model_dict.items():\n",
    "    # Create an instance of the nlp_random_search_modeler function\n",
    "    # with the specified model, CountVectorizer, cross-validation strategy, vectorizer parameters, and model parameters\n",
    "    nlp = nlp_random_search_modeler(dic['mod_instant'], \n",
    "                                    CountVectorizer(), \n",
    "                                    cross_validation=kf, \n",
    "                                    vectorizer_params=vec_params, \n",
    "                                    model_params=dic['mod_param'])\n",
    "    \n",
    "    # Fit the nlp_random_search_modeler object to the training data\n",
    "    nlp.fit(X_train, y_train)\n",
    "    \n",
    "    # Assign the fitted model to the models_cvec dictionary using the corresponding key\n",
    "    models_cvec[key] = nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5414a5a-1c5f-4389-a25b-d9ab7d94b577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5h 13min 26s, sys: 2min 36s, total: 5h 16min 3s\n",
      "Wall time: 5h 18min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "models_tvec = {}\n",
    "for key, dic in model_dict.items():\n",
    "    nlp = nlp_random_search_modeler(dic['mod_instant'], \n",
    "                                    TfidfVectorizer(), \n",
    "                                    cross_validation=kf, \n",
    "                                    vectorizer_params=vec_params, \n",
    "                                    model_params=dic['mod_param'])\n",
    "    nlp.fit(X_train, y_train)\n",
    "    models_tvec[key] = nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e083e0b-7843-483d-be1d-d04fecfe1c92",
   "metadata": {},
   "source": [
    "## Models Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b771a5-3678-409e-852b-4405b6d5a7d1",
   "metadata": {},
   "source": [
    "### Performance of the models with CountVectorizer as text processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7eaeb977-4744-4577-bae6-d1b8fd40fa11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb model - Train Accuracy: 0.9204545454545454\n",
      "nb model - Validation Accuracy: 0.9027484143763214\n",
      "nb model - Validation AUC: 0.949950624855134\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.84      0.86       688\n",
      "           1       0.91      0.94      0.92      1204\n",
      "\n",
      "    accuracy                           0.90      1892\n",
      "   macro avg       0.90      0.89      0.89      1892\n",
      "weighted avg       0.90      0.90      0.90      1892\n",
      "\n",
      "\n",
      "\n",
      "logreg model - Train Accuracy: 0.9788583509513742\n",
      "logreg model - Validation Accuracy: 0.9038054968287527\n",
      "logreg model - Validation AUC: 0.9540316194081743\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.87       688\n",
      "           1       0.93      0.92      0.92      1204\n",
      "\n",
      "    accuracy                           0.90      1892\n",
      "   macro avg       0.90      0.90      0.90      1892\n",
      "weighted avg       0.90      0.90      0.90      1892\n",
      "\n",
      "\n",
      "\n",
      "rf model - Train Accuracy: 0.9951109936575053\n",
      "rf model - Validation Accuracy: 0.8953488372093024\n",
      "rf model - Validation AUC: 0.9552919531793248\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.80      0.85       688\n",
      "           1       0.89      0.95      0.92      1204\n",
      "\n",
      "    accuracy                           0.90      1892\n",
      "   macro avg       0.90      0.88      0.88      1892\n",
      "weighted avg       0.90      0.90      0.89      1892\n",
      "\n",
      "\n",
      "\n",
      "svc model - Train Accuracy: 0.9630021141649049\n",
      "svc model - Validation Accuracy: 0.9053911205073996\n",
      "svc model - Validation AUC: 0.9505463860774165\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87       688\n",
      "           1       0.92      0.93      0.93      1204\n",
      "\n",
      "    accuracy                           0.91      1892\n",
      "   macro avg       0.90      0.90      0.90      1892\n",
      "weighted avg       0.91      0.91      0.91      1892\n",
      "\n",
      "\n",
      "\n",
      "gb model - Train Accuracy: 0.9611522198731501\n",
      "gb model - Validation Accuracy: 0.8937632135306554\n",
      "gb model - Validation AUC: 0.954888742949857\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.85       688\n",
      "           1       0.90      0.93      0.92      1204\n",
      "\n",
      "    accuracy                           0.89      1892\n",
      "   macro avg       0.89      0.88      0.88      1892\n",
      "weighted avg       0.89      0.89      0.89      1892\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in ['nb', 'logreg', 'rf', 'svc', 'gb']:\n",
    "\n",
    "    print(f\"{model} model - Train Accuracy:\", models_cvec[model].score(X_train, y_train))\n",
    "    print(f\"{model} model - Validation Accuracy:\", models_cvec[model].score(X_val, y_val))\n",
    "    print(f\"{model} model - Validation AUC:\", roc_auc_score(y_val, models_cvec[model].predict_proba(X_val)[:, 1]))\n",
    "    print('\\n')\n",
    "    print(classification_report(y_val, models_cvec[model].predict(X_val)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df60b5bf-bc38-4252-ba04-771a34e91f72",
   "metadata": {},
   "source": [
    "### Performance of the models with TfidfVectorizer as text processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e702be8-b4f0-4c89-b468-2aa9cf44ef32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb model - Train Accuracy score: 0.9187367864693446\n",
      "nb model - Validation Accuracy score: 0.8969344608879493\n",
      "nb model - Validation AUC: 0.9595860214015297\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.81      0.85       688\n",
      "           1       0.90      0.95      0.92      1204\n",
      "\n",
      "    accuracy                           0.90      1892\n",
      "   macro avg       0.90      0.88      0.89      1892\n",
      "weighted avg       0.90      0.90      0.90      1892\n",
      "\n",
      "\n",
      "\n",
      "logreg model - Train Accuracy score: 0.9141120507399577\n",
      "logreg model - Validation Accuracy score: 0.8990486257928119\n",
      "logreg model - Validation AUC: 0.9543491172834736\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.82      0.85       688\n",
      "           1       0.90      0.95      0.92      1204\n",
      "\n",
      "    accuracy                           0.90      1892\n",
      "   macro avg       0.90      0.88      0.89      1892\n",
      "weighted avg       0.90      0.90      0.90      1892\n",
      "\n",
      "\n",
      "\n",
      "rf model - Train Accuracy score: 0.9994714587737844\n",
      "rf model - Validation Accuracy score: 0.8932346723044398\n",
      "rf model - Validation AUC: 0.9583594896855443\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.79      0.84       688\n",
      "           1       0.89      0.95      0.92      1204\n",
      "\n",
      "    accuracy                           0.89      1892\n",
      "   macro avg       0.90      0.87      0.88      1892\n",
      "weighted avg       0.89      0.89      0.89      1892\n",
      "\n",
      "\n",
      "\n",
      "svc model - Train Accuracy score: 0.9800475687103594\n",
      "svc model - Validation Accuracy score: 0.9080338266384778\n",
      "svc model - Validation AUC: 0.9589202416364059\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87       688\n",
      "           1       0.92      0.94      0.93      1204\n",
      "\n",
      "    accuracy                           0.91      1892\n",
      "   macro avg       0.90      0.90      0.90      1892\n",
      "weighted avg       0.91      0.91      0.91      1892\n",
      "\n",
      "\n",
      "\n",
      "gb model - Train Accuracy score: 0.9997357293868921\n",
      "gb model - Validation Accuracy score: 0.9022198731501057\n",
      "gb model - Validation AUC: 0.9583256876303793\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.82      0.86       688\n",
      "           1       0.90      0.95      0.92      1204\n",
      "\n",
      "    accuracy                           0.90      1892\n",
      "   macro avg       0.90      0.89      0.89      1892\n",
      "weighted avg       0.90      0.90      0.90      1892\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in ['nb', 'logreg', 'rf', 'svc', 'gb']:\n",
    "    \n",
    "    print(f\"{model} model - Train Accuracy score:\", models_tvec[model].score(X_train, y_train))\n",
    "    print(f\"{model} model - Validation Accuracy score:\", models_tvec[model].score(X_val, y_val))\n",
    "    print(f\"{model} model - Validation AUC:\", roc_auc_score(y_val, models_tvec[model].predict_proba(X_val)[:, 1]))\n",
    "    print('\\n')\n",
    "    print(classification_report(y_val, models_tvec[model].predict(X_val)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b38b998-2b2c-460a-9231-84f8e637b9ad",
   "metadata": {},
   "source": [
    "After evaluating the performance of all implemented models, it has been determined that the Support Vector Machine (SVC) model, in conjunction with the TfidfVectorizer and the specified hyperparameters, demonstrates superior performance compared to the other models. As a result, it will be saved for the final evaluation using the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12e047a8-6c11-46af-bd77-ecfcac535ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = {\n",
    "    'mod_instant': model_dict['svc']['mod_instant'], \n",
    "    'model': models_tvec['svc'],\n",
    "    'vectorizer': TfidfVectorizer()\n",
    "             }\n",
    "\n",
    "with open('../data/best_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
